{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c093dabf",
   "metadata": {},
   "source": [
    "# Model Learning: $L^*$\n",
    "\n",
    "Let us fix some unknown regular language $L$ that we want to learn. Your objectives will be to:\n",
    "\n",
    "  1. implement an observation table;\n",
    "  2. implement $L^*$;\n",
    "  3. measure the number of queries that are used to learn an automaton;\n",
    "  4. test different approaches to process a counterexample; and\n",
    "  5. apply $L^*$ to discover a bug in an implementation.\n",
    "\n",
    "Throughout this notebook, the functions and parts you have to work on are tagged with FIXME. You are allowed to define new functions and class fields.\n",
    "\n",
    "You need to install the AALpy Python library (`pip install aalpy`), and [GraphViz](https://graphviz.org/) (`sudo apt install graphviz` on Debian-based distributions).\n",
    "\n",
    "Two new types are defined:\n",
    "  - `Symbol` (which is equivalent to `str`); and\n",
    "  - `Word` (which is a list of `Symbol`).\n",
    "The functions defined in the cells of this notebook use these types for clarity. Moreover, the global variable `empty_word` is defined (as the empty list). Finally, the following functions are available:\n",
    "  - `concat(w1: Word, w2: Word) -> Word`, which takes two words $w_1$ and $w_2$ and returns the word $w_1 \\cdot w_2$;\n",
    "  - `append_symbol(w: Word, s: Symbol) -> Word`, which takes a word $w$ and a symbol $s$ and returns $w \\cdot s$;\n",
    "  - `prepend_symbol(s: Symbol, w: Word) -> Word`, which takes a word $w$ and a symbol $s$ and returns $s \\cdot w$;\n",
    "  - `prefixes(w: Word) -> List[Word]`, which returns the list of all the prefixes of $w$; and\n",
    "  - `suffixes(w: Word) -> List[Word]`, which returns the list of all the suffixes of $w$."
   ]
  },
  {
   "cell_type": "code",
   "id": "da88fd18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T12:22:29.631396Z",
     "start_time": "2025-07-03T12:22:29.626920Z"
    }
   },
   "source": [
    "import aalpy\n",
    "from aalpy import SUL, Oracle, Dfa, DfaState\n",
    "from statistics import fmean\n",
    "import matplotlib.pyplot as plt\n",
    "import tests\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "from typing import *\n",
    "from utils import *"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "id": "9234ce45",
   "metadata": {},
   "source": [
    "## 0 - Relevant AALpy methods\n",
    "\n",
    "Throughout these exercises, you will manipulate instances of two AALpy classes:\n",
    "  - `SUL` implements a membership oracle:\n",
    "    - `sul.query(word: Word)`, returns a list of Booleans, where the $i$-th Boolean is true if the automaton accepts the prefix of length $i$ of `word`. Formally, if `word` is the sequence of input symbols $i_1 i_2 \\dotsb i_n$, the function returns a list $[o_1, o_2, \\dotsc, o_n]$ such that, for every $j$, $o_j$ is true if and only if $i_1 \\dotsb i_j \\in L$.\n",
    "  - `Oracle` implements an equivalence oracle:\n",
    "    - `oracle.find_cex(hypothesis: DFA)`, returns a word that is a counterexample, or None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2b5091",
   "metadata": {},
   "source": [
    "## 1 - Observation table\n",
    "\n",
    "The first exercise focuses on implementing an observation table.\n",
    "\n",
    "### Recap\n",
    "\n",
    "An *observation table* is a tuple $\\mathcal{O} = (R, S, T)$ where:\n",
    "\n",
    "  - $R$ is a non-empty, finite, prefix-closed of *representatives*.\n",
    "  - $S$ is a non-empty, finite, suffix-closed of *separators*.\n",
    "  - $T : (R \\cup R \\cdot \\Sigma) \\cdot S \\to \\mathbb{B}$ records whether the word $r \\cdot s$ (with $r \\in R \\cup R \\cdot \\Sigma$ and $s \\in S$) belong to $L$.\n",
    "\n",
    "An observation table $\\mathcal{O}$ induces an equivalence relation $\\equiv{} \\subseteq (R \\cup R \\cdot \\Sigma) \\times (R \\cup R \\cdot \\Sigma)$: for every $r, r' \\in R$, we have $r \\equiv r'$ if and only if, for every $s \\in S$, $T(r \\cdot s) = T(r' \\cdot s)$.\n",
    "\n",
    "An observation table is said *closed* if, for every $r \\in R \\cdot \\Sigma$, there exists some $r' \\in R$ such that $r \\equiv r'$.\n",
    "\n",
    "An observation table is said *consistent* if, for every $a \\in \\Sigma$ and $r, r' \\in R$ such that $r \\equiv r'$, it holds that $r \\cdot a \\equiv r' \\cdot a$.\n",
    "\n",
    "Once the table is closed and consistent, it is possible to construct a hypothesis DFA from the equivalence classes of $\\equiv$.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "Two classes are provided:\n",
    "\n",
    "  - `Row`, which stores:\n",
    "    - the word labelling the row (i.e., the word in $R \\cup R \\cdot \\Sigma$),\n",
    "    - whether the word belongs to $R$ or $R \\cdot \\Sigma$, and\n",
    "    - the content of the row, as a list of Booleans.\n",
    "  - `ObservationTable` which implements an observation table. The following fields are defined:\n",
    "    - `sul` is the membership oracle,\n",
    "    - `alphabet` is the input alphabet,\n",
    "    - `rows` is a list of instances of `Row`, and\n",
    "    - `separators` is a list of separators, i.e., $S$.\n",
    "\n",
    "`ObservationTable` also declares methods. Some are them are already implemented. You are tasked with implementing the following functions:\n",
    "\n",
    "  1. `get_representatives()` that returns $R$.\n",
    "  2. `get_row(word: Word)` that returns the row for the given word. If the row is not present, the function returns None.\n",
    "  3. `add_row(word: Word, representative: bool)` that adds a new row (i.e., a row for a new element of $R \\cup R \\cdot \\Sigma$) inside the table. This function must fill $T$.\n",
    "  4. `add_representative(word: Word)` that adds a new element in $R$ and its corresponding row. Note that the word may already exist in $R \\cdot \\Sigma$. You can assume that the prefixes of the word are already in $R$. This function must fill the missing values in $T$.\n",
    "  5. `add_separator(word: Word)` that adds a new element in $S$. You can assume that the suffixes of the word are already in $S$. This function must fill the missing values in $T$.\n",
    "  6. `find_unclosed()` that returns a row in the lower part of the table that has no equivalent row in the upper part of the table, or None.\n",
    "  7. `make_closed(row: Row)` that fixes the unclosedness of `row`.\n",
    "  8. `find_inconsistency()` that returns a tuple with two rows whose words are $w_1$ and $w_2$, and a symbol $a$ such that $w_1 \\cdot a \\not\\equiv w_2 \\cdot a$.\n",
    "  9. `make_consistent(row1: Row, row2: Row, symbol: Symbol)` that fixes the inconsistency.\n",
    "  10. `make_closed_and_consistent()` that ensures that the table is closed and consistent.\n",
    "  11. `process_counterexample(word: Word)` that treats a counterexample by adding each prefix of word as a new representative.\n",
    "\n",
    "Unit tests are automatically executed at the end of the cell."
   ]
  },
  {
   "cell_type": "code",
   "id": "9cd31dd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T12:23:27.084123Z",
     "start_time": "2025-07-03T12:23:27.043410Z"
    }
   },
   "source": [
    "class Row:\n",
    "    def __init__(self, word: Word, representative: bool, content: List[bool]):\n",
    "        self.word = word\n",
    "        self.representative = representative\n",
    "        self.content = content\n",
    "\n",
    "    def equivalent(self, row: \"Row\") -> bool:\n",
    "        return self.content == row.content\n",
    "\n",
    "\n",
    "class ObservationTable:\n",
    "    def __init__(self, sul: SUL, alphabet: List[Symbol]):\n",
    "        self.sul: SUL = sul\n",
    "        self.alphabet: List[Symbol] = alphabet\n",
    "        self.rows: List[Row] = []\n",
    "        self.separators: List[Word] = []\n",
    "        self.add_representative(empty_word)\n",
    "        self.add_separator(empty_word)\n",
    "        print(self.sul.query(empty_word))\n",
    "\n",
    "    def number_rows(self) -> int:\n",
    "        return len(self.rows)\n",
    "\n",
    "    def number_separators(self) -> int:\n",
    "        return len(self.separators)\n",
    "\n",
    "    def construct_hypothesis(self) -> Dfa:\n",
    "        selected_rows = []\n",
    "        for row in filter(lambda r: r.representative, self.rows):\n",
    "            if all(row.content != r.content for r in selected_rows):\n",
    "                selected_rows.append(row)\n",
    "        empty_row = self.get_row(empty_word)\n",
    "        for i, selected in enumerate(selected_rows):\n",
    "            if empty_row.equivalent(selected):\n",
    "                initial_index = i\n",
    "\n",
    "        states = [\n",
    "            DfaState(f\"s{i}\", selected_rows[i].content[0])\n",
    "            for i in range(len(selected_rows))\n",
    "        ]\n",
    "        for i, selected in enumerate(selected_rows):\n",
    "            for symbol in self.alphabet:\n",
    "                target_row = self.get_row(append_symbol(selected.word, symbol))\n",
    "                for j, sel in enumerate(selected_rows):\n",
    "                    if sel.equivalent(target_row):\n",
    "                        states[i].transitions[symbol] = states[j]\n",
    "        return Dfa(states[initial_index], states)\n",
    "\n",
    "    def get_representatives(self) -> List[Word]:\n",
    "        return [row.word for row in self.rows if row.representative]\n",
    "\n",
    "    def get_row(self, word: Word) -> Row:\n",
    "        for row in filter(lambda r: r.word == word, self.rows):\n",
    "            return row\n",
    "        return None\n",
    "\n",
    "    def add_row(self, word: Word, representative: bool) -> None:\n",
    "        if not self.get_row(word) is None:\n",
    "            return\n",
    "        content = []\n",
    "        for seperator in self.separators:\n",
    "            accept = self.sul.query(word + seperator).pop()\n",
    "            content.append(accept)\n",
    "        self.rows.append(Row(word, representative, content))\n",
    "\n",
    "    def add_representative(self, representative: Word) -> None:\n",
    "        row = self.get_row(representative)\n",
    "        if row == None:\n",
    "            self.add_row(representative, True)\n",
    "        elif not row.representative:\n",
    "            row.representative = True\n",
    "\n",
    "        for symbol in self.alphabet:\n",
    "            self.add_row(append_symbol(representative, symbol), False)\n",
    "\n",
    "    def add_separator(self, separator: Word) -> None:\n",
    "        if separator in self.separators:\n",
    "            return\n",
    "        self.separators.append(separator)\n",
    "        for row in self.rows:#type Row\n",
    "            accept = self.sul.query(row.word + separator).pop()\n",
    "            row.content.append(accept)\n",
    "        pass\n",
    "\n",
    "    def find_unclosed(self) -> Row or None:\n",
    "        for row in filter(lambda r: not r.representative, self.rows):\n",
    "            found = False\n",
    "            for row1 in filter(lambda r: r.representative, self.rows):\n",
    "                if row.content == row1.content:\n",
    "                    found = True\n",
    "            if not found:\n",
    "                return row\n",
    "        return None\n",
    "\n",
    "    def make_closed(self, row: Row) -> None:\n",
    "        self.add_representative(row.word)\n",
    "\n",
    "    def find_inconsistency(self) -> Tuple[Row, Row, Symbol]:\n",
    "        # Get the represent\n",
    "        representives1 = self.get_representatives()\n",
    "        representives2 = self.get_representatives()\n",
    "        for word1 in representives1:#type: Word\n",
    "            for word2 in representives2:#type: Word\n",
    "                # Check if the two words are equivalent but not the same\n",
    "                if self.get_row(word1).equivalent(self.get_row(word2)) and word1 != word2:\n",
    "                    # For each symbol in the alphabet, check if appending it to both words leads to an inconsistency\n",
    "                    for symbol in self.alphabet:\n",
    "                        # Append the symbol to both words and get the new rows\n",
    "                        new_row1 = self.get_row(append_symbol(word1, symbol))\n",
    "                        new_row2 = self.get_row(append_symbol(word2, symbol))\n",
    "                        # If either row is None, it means the word was not found\n",
    "                        if new_row1 is None or new_row2 is None:\n",
    "                            # print(\"Row not found for\", append_symbol(word1, symbol), \"or\", append_symbol(word2, symbol), flush=True)\n",
    "                            continue\n",
    "                        # If the new rows are not equivalent, we found an inconsistency\n",
    "                        if not new_row1.equivalent(new_row2):\n",
    "                            # print(\"INCONSISTENCY FOUND\", flush=True)\n",
    "                            return new_row1, new_row2, symbol\n",
    "        return None\n",
    "\n",
    "    def make_consistent(self, row1: Row, row2: Row, symbol: Symbol) -> None:\n",
    "        # print(\"MAKE CONSISTENT\", flush=True)\n",
    "        # print(\"ADD SYMBOL\" + symbol, flush=True)\n",
    "        # Check if the content of the rows differ\n",
    "        for i in range(len(row1.content)):\n",
    "            # If they differ, add a separator and return\n",
    "            if row1.content[i] != row2.content[i]:\n",
    "                # print(\"ADD SEPARATOR\", flush=True)\n",
    "                # Append the symbol to the separator and add it\n",
    "                addVal = prepend_symbol(symbol, self.separators[i])\n",
    "                self.add_separator(addVal)\n",
    "                return\n",
    "\n",
    "\n",
    "    def make_closed_and_consistent(self) -> None:\n",
    "        # print(\"MAKE CLOSED\", flush=True)\n",
    "        while True:\n",
    "            unclosed = self.find_unclosed()\n",
    "            if unclosed:\n",
    "                self.make_closed(unclosed)\n",
    "                continue\n",
    "\n",
    "            inconsistency = self.find_inconsistency()\n",
    "            if inconsistency:\n",
    "                self.make_consistent(*inconsistency)\n",
    "                continue\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "    def process_counterexample(self, word: Word) -> None:\n",
    "        for prefix in prefixes(word):\n",
    "            self.add_representative(prefix)\n",
    "\n",
    "tests.run_tests_observation_table(ObservationTable)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "ADD SEPARATOR ['b']\n",
      "TESTING SEPARATOR ['b']\n",
      "ADD SEPARATOR ['a']\n",
      "TESTING SEPARATOR ['a']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "ADD SEPARATOR ['b']\n",
      "TESTING SEPARATOR ['b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.014s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "id": "178da5f0",
   "metadata": {},
   "source": [
    "## 2 - $L^*$\n",
    "\n",
    "Implement $L^*$, using `ObservationTable`. The `lstar` function takes the following parameter:\n",
    "  - `sul: SUL`, the membership oracle;\n",
    "  - `alphabet: List[Symbol]`, the alphabet;\n",
    "  - `eq_oracle: Oracle`, the equivalence oracle; and\n",
    "  - `tableType`, the type of the observation table. This will permit us to use a different implementation in Section 4.\n",
    "\n",
    "Unit tests are automatically executed at the end of the cell."
   ]
  },
  {
   "cell_type": "code",
   "id": "c2b71650",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T12:24:11.157276Z",
     "start_time": "2025-07-03T12:24:11.123362Z"
    }
   },
   "source": [
    "def lstar(sul: SUL, alphabet: List[Symbol], eq_oracle: Oracle, tableType) -> Dfa:\n",
    "    table = tableType(sul, alphabet)\n",
    "    counter = 0\n",
    "    while True:\n",
    "        # print(\"MAKE CONSISTENT AND CLOSED\", flush=True)\n",
    "        table.make_closed_and_consistent()\n",
    "        # print(\"Seperators: \" + str(table.separators), flush=True)\n",
    "        # print(\"Representatives: \" + \", \".join(map(str, table.get_representatives())), flush=True)\n",
    "        # print(\"Rows: \" + str(table.number_rows()), flush=True)\n",
    "        # print(\"CONSTRUCT HYPOTHESIS\", flush=True)\n",
    "        hypothesis = table.construct_hypothesis()\n",
    "        w = eq_oracle.find_cex(hypothesis)\n",
    "        if w is None:\n",
    "            print(\"DONE\", flush=True)\n",
    "            return hypothesis\n",
    "\n",
    "        print(w)\n",
    "        # print(\"PROCESS CE\", flush=True)\n",
    "        table.process_counterexample(w)\n",
    "        counter += 1\n",
    "        if counter == 100:\n",
    "            return hypothesis\n",
    "\n",
    "tests.run_tests_lstar(ObservationTable, lstar)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n",
      "['a', 'b']\n",
      "ADD SEPARATOR ['b']\n",
      "TESTING SEPARATOR ['b']\n",
      "ADD SEPARATOR ['a']\n",
      "TESTING SEPARATOR ['a']\n",
      "DONE\n",
      "[False]\n",
      "['b', 'b', 'a', 'a', 'a', 'a', 'b', 'a', 'a']\n",
      "ADD SEPARATOR ['b']\n",
      "TESTING SEPARATOR ['b']\n",
      "ADD SEPARATOR ['a']\n",
      "TESTING SEPARATOR ['a']\n",
      "DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n",
      "['i3', 'i3']\n",
      "ADD SEPARATOR ['i3']\n",
      "TESTING SEPARATOR ['i3']\n",
      "ADD SEPARATOR ['i1']\n",
      "TESTING SEPARATOR ['i1']\n",
      "DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.025s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "id": "85e62466",
   "metadata": {},
   "source": [
    "## 3 - Experimental evaluation\n",
    "\n",
    "We now measure how many queries are used by $L^*$ to infer a correct DFA, as well as the size of the table.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "  1. Implement `measure_lstar(tableType, states_range, alphabet_range, repetitions)` that runs $L^*$ on multiple instances and measure, on average, how many queries are performed per number of input symbols and number of states of the target automaton. The result must be a dictionary whose keys are the sizes of the alphabet, and whose values are dictionaries whose keys are the sizes of the target automata, and whose values are tuples with:\n",
    "    - the average number of membership queries,\n",
    "    - the average number of equivalence queries,\n",
    "    - the average number of representatives (i.e., the size of $R$), and\n",
    "    - the average number of separators (i.e., the size of $S$).\n",
    "  2. Implement `plot(queries)` that create multiple figures: for each alphabet size, plot, per number of states, the numbers of membership queries, equivalence queries, representatives, and separators. The `queries` argument is the result of `measure_lstar`.\n",
    "\n",
    "To help you implementing the functions, you can call `run_experiment(tableType, lstar, num_states, alphabet_size) -> Tuple[int, int, int, int]` which generates a random alphabet of the given size and a random DFA of the given size, and run the provided `lstar` method with `tableType`. This function returns a tuple with the number of membership queries, of equivalence queries, of representatives, and of separators."
   ]
  },
  {
   "cell_type": "code",
   "id": "cdcb28ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T12:30:04.364177Z",
     "start_time": "2025-07-03T12:30:03.966359Z"
    }
   },
   "source": [
    "def measure_lstar(tableType, states_range: range, alphabet_range: range, repetitions: int) -> Dict[int, Dict[int, Tuple[float, float, float, float]]]:\n",
    "    random.seed(35) # To generate the same random automata each run\n",
    "\n",
    "    big_d = dict()\n",
    "    for alphabet in alphabet_range:\n",
    "        small_d = dict()\n",
    "        for state in states_range:\n",
    "            total_MQ = 0\n",
    "            total_EQ = 0\n",
    "            total_prep = 0\n",
    "            total_sep = 0\n",
    "            for i in range(repetitions):\n",
    "                mq, eq, reps, seps = run_experiment(tableType, lstar, state, alphabet)\n",
    "                total_MQ += mq\n",
    "                total_EQ += eq\n",
    "                total_prep += reps\n",
    "                total_sep += seps\n",
    "            small_d[state] = (total_MQ/repetitions, total_EQ/repetitions, total_prep/repetitions, total_sep/repetitions)\n",
    "        big_d[alphabet] = small_d\n",
    "    print(big_d)\n",
    "    return big_d\n",
    "\n",
    "\n",
    "def plot(queries: Dict[Tuple[int, int], Tuple[float, float]]) -> None:\n",
    "    n_rows = len(queries)\n",
    "    n_columns = 4\n",
    "    \n",
    "    # FIXME\n",
    "    pass\n",
    "\n",
    "\n",
    "results = measure_lstar(ObservationTable, range(5, 31, 5), range(4, 9, 2), 100)\n",
    "plot(results)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'override' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[64]\u001B[39m\u001B[32m, line 32\u001B[39m\n\u001B[32m     28\u001B[39m     \u001B[38;5;66;03m# FIXME\u001B[39;00m\n\u001B[32m     29\u001B[39m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m32\u001B[39m results = \u001B[43mmeasure_lstar\u001B[49m\u001B[43m(\u001B[49m\u001B[43mObservationTable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m31\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[32;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m9\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     33\u001B[39m plot(results)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[64]\u001B[39m\u001B[32m, line 13\u001B[39m, in \u001B[36mmeasure_lstar\u001B[39m\u001B[34m(tableType, states_range, alphabet_range, repetitions)\u001B[39m\n\u001B[32m     11\u001B[39m total_sep = \u001B[32m0\u001B[39m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(repetitions):\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m     mq, eq, reps, seps = \u001B[43mrun_experiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtableType\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlstar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malphabet\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     14\u001B[39m     total_MQ += mq\n\u001B[32m     15\u001B[39m     total_EQ += eq\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/school/2025-2026/Software Testing/Software_testing/lstar/utils.py:35\u001B[39m, in \u001B[36mrun_experiment\u001B[39m\u001B[34m(tableType, lstar, num_states, alphabet_size)\u001B[39m\n\u001B[32m     34\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mrun_experiment\u001B[39m(tableType, lstar, num_states: \u001B[38;5;28mint\u001B[39m, alphabet_size: \u001B[38;5;28mint\u001B[39m) -> Tuple[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mint\u001B[39m]:\n\u001B[32m---> \u001B[39m\u001B[32m35\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mclass\u001B[39;49;00m\u001B[38;5;250;43m \u001B[39;49m\u001B[34;43;01mCounterEqOracle\u001B[39;49;00m\u001B[43m(\u001B[49m\u001B[43maalpy\u001B[49m\u001B[43m.\u001B[49m\u001B[43mRandomWalkEqOracle\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     36\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mdef\u001B[39;49;00m\u001B[38;5;250;43m \u001B[39;49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malphabet\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msul\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43maalpy\u001B[49m\u001B[43m.\u001B[49m\u001B[43mSUL\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     37\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43malphabet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msul\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/school/2025-2026/Software Testing/Software_testing/lstar/utils.py:40\u001B[39m, in \u001B[36mrun_experiment.<locals>.CounterEqOracle\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     37\u001B[39m     \u001B[38;5;28msuper\u001B[39m().\u001B[34m__init__\u001B[39m(alphabet, sul)\n\u001B[32m     38\u001B[39m     \u001B[38;5;28mself\u001B[39m.counter = \u001B[32m0\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m40\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m     41\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfind_cex\u001B[39m(\u001B[38;5;28mself\u001B[39m, hypothesis):\n\u001B[32m     42\u001B[39m     \u001B[38;5;28mself\u001B[39m.counter += \u001B[32m1\u001B[39m\n\u001B[32m     43\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m().find_cex(hypothesis)\n",
      "\u001B[31mNameError\u001B[39m: name 'override' is not defined"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "id": "801bd625",
   "metadata": {},
   "source": [
    "## 4 - Counterexample processing\n",
    "\n",
    "Adding all the prefixes of the counterexample as new representatives in the observation table is not the only way to process a counterexample. Another possibility is to add all its suffixes as new separators. Let us explore this, and experimentally compare both approaches.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "  1. Implement the following `process_counterexample(word: Word)` that adds the suffixes of the word as new separators.\n",
    "  2. Compare the experimental results of adding the prefixes or the suffixes."
   ]
  },
  {
   "cell_type": "code",
   "id": "838f4539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:26:43.447666Z",
     "start_time": "2025-07-02T16:26:43.418770Z"
    }
   },
   "source": [
    "class ObservationTableSuffixes(ObservationTable):\n",
    "    @override\n",
    "    def process_counterexample(self, word: Word):\n",
    "        suff = suffixes(word)\n",
    "        \n",
    "        for element in suff:\n",
    "            if element != word:\n",
    "                self.add_separator(element)\n",
    "\n",
    "        #we moeten hier wss hetzelfde doen als in oef 1\n",
    "\n",
    "        return\n",
    "\n",
    "tests.run_tests_lstar(ObservationTableSuffixes, lstar)\n",
    "\n",
    "results = measure_lstar(ObservationTableSuffixes, range(5, 31, 5), range(4, 9, 2), 100)\n",
    "plot(results)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n",
      "[False]\n",
      "[True]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 15\u001B[39m\n\u001B[32m     12\u001B[39m tests.run_tests_lstar(ObservationTableSuffixes, lstar)\n\u001B[32m     14\u001B[39m results = measure_lstar(ObservationTableSuffixes, \u001B[38;5;28mrange\u001B[39m(\u001B[32m5\u001B[39m, \u001B[32m31\u001B[39m, \u001B[32m5\u001B[39m), \u001B[38;5;28mrange\u001B[39m(\u001B[32m4\u001B[39m, \u001B[32m9\u001B[39m, \u001B[32m2\u001B[39m), \u001B[32m100\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m \u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresults\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 8\u001B[39m, in \u001B[36mplot\u001B[39m\u001B[34m(queries)\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mplot\u001B[39m(queries: Dict[Tuple[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mint\u001B[39m], Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]]) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m     n_rows = \u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mqueries\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m     n_columns = \u001B[32m4\u001B[39m\n\u001B[32m     10\u001B[39m     \u001B[38;5;66;03m# FIXME\u001B[39;00m\n",
      "\u001B[31mTypeError\u001B[39m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "7b74fbc3",
   "metadata": {},
   "source": [
    "## 5 - Learning to model check\n",
    "\n",
    "To conclude these exercises, we apply $L^*$ to infer a DFA $\\mathcal{A}$ from an existing implementation. Once $\\mathcal{A}$ is known, we can check whether the implementation behaves as expected.\n",
    "\n",
    "In order to obtain $\\mathcal{A}$, we will rely on *probably approximately correct* learning. That is, we can query the implementation for membership queries, but equivalence queries are approximated by testing random words. A SUL (i.e., a membership oracle) is already provided. You are tasked with implementing the equivalence oracle, and checking whether the resulting automaton behaves as expected.\n",
    "\n",
    "Recall that the number of words to test is given by\n",
    "$$r_i = \\left\\lceil \\frac{1}{\\varepsilon} \\left(\\ln \\frac{1}{\\delta} + (\\ln 2) (i + 1)\\right) \\right\\rceil,$$\n",
    "where $i$ is the number of already testes hypotheses.\n",
    "\n",
    "### Description of the system\n",
    "\n",
    "We consider a printer secured by a keycard. Initially, it is powered off. When the machine is powered on, it boots in its locked status. In order to access the printer's functionalities, the user must swipe their keycard to unlock the printer.\n",
    "\n",
    "Once the printer is unlocked, the user has two possibilities:\n",
    "  - they can either swipe their keycard again to lock the system, or\n",
    "  - print a document.\n",
    "If the printer is unlocked but no action occurs within a given time window, it automatically locks itself.\n",
    "\n",
    "When the printer is done printing a document, it returns in its unlocked status by default. The user may swipe their keycard to lock the system during printing (in which case, the printer will still finish its job).\n",
    "\n",
    "At any point, the power may be cut off at any point, stopping the printer.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "  1. Draw a DFA modeling the printer behavior, using $\\Sigma = \\{\\mathrm{power}, \\mathrm{keycard}, \\mathrm{timeout}, \\mathrm{print}, \\mathrm{done}\\}$.\n",
    "  2. Fill the functions of `RandomWordsEQ`.\n",
    "  3. Run $L^*$ with the given SUL and an instance of `RandomWordsEQ`.\n",
    "  4. Is the automaton correct? (Hint: the `Dfa` class of AALpy implements a `visualize` method.)"
   ]
  },
  {
   "cell_type": "code",
   "id": "4134a20f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T15:58:20.811937Z",
     "start_time": "2025-07-02T15:58:20.787146Z"
    }
   },
   "source": [
    "class RandomWordsEQ(Oracle):\n",
    "    def __init__(self, alphabet: List[Symbol], sul: SUL, accuracy: float, confidence: float):\n",
    "        super().__init__(alphabet, sul)\n",
    "        self.n_queries = 0\n",
    "        self.accuracy = accuracy\n",
    "        self.confidence = confidence\n",
    "        # You also have access to self.sul and self.alphabet\n",
    "\n",
    "    def _get_hypo_output(self, hypothesis: Dfa, word: Word) -> bool:\n",
    "        return hypothesis.compute_output_seq(hypothesis.initial_state, word)[-1]\n",
    "\n",
    "    def _number_words(self):\n",
    "         r = (1/self.accuracy) * (math.log(1/self.confidence, math.e) + (math.log(2, math.e) * (self.n_queries+1)))\n",
    "         return r\n",
    "\n",
    "    def _generate_word(self):\n",
    "        # FIXME: generate a random word.\n",
    "        # For practical reasons, you can assume the distribution over the words to be uniform.\n",
    "        # Moreover, you can limit the length of the words to 20 symbols.\n",
    "        length = random.randint(1, 20)\n",
    "        word = \"\"\n",
    "        for i in range(0, length):\n",
    "            word.append(random.choice(self.alphabet))\n",
    "        return word\n",
    "\n",
    "    @override\n",
    "    def find_cex(self, hypothesis: Dfa) -> Word:\n",
    "        number_words = self._number_words()\n",
    "        self.n_queries += 1\n",
    "        for i in range(0, number_words):\n",
    "                word = self._generate_word()\n",
    "                if self._get_hypo_output(hypothesis, word) == sul.query(word):\n",
    "                    return word\n",
    "        pass\n",
    "\n",
    "\n",
    "random.seed(35)\n",
    "sul = get_sul()\n",
    "alphabet = [\"power\", \"keycard\", \"timeout\", \"print\", \"done\"]\n",
    "\n",
    "# this is the most boring subject ev er\n",
    "\n",
    "# this is more beyond than testing\n",
    "# FIXME: construct an instance of RandomWordsEQ and run lstar\n",
    "\n",
    "# i dont care\n",
    "rafsdfiojsmdflkjsmdflksjl = RandomWordsEQ(alphabet, sul, 0.9, 0.05)\n",
    "dfa = lstar(sul, alphabet, rafsdfiojsmdflkjsmdflksjl, ObservationTable).visualize()\n",
    "\n",
    "# You may need to test multiple values for the accuracy and the confidence before obtaining a good model."
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'visualize'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 54\u001B[39m\n\u001B[32m     47\u001B[39m \u001B[38;5;66;03m# this is the most boring subject ev er\u001B[39;00m\n\u001B[32m     48\u001B[39m \n\u001B[32m     49\u001B[39m \u001B[38;5;66;03m# this is more beyond than testing\u001B[39;00m\n\u001B[32m     50\u001B[39m \u001B[38;5;66;03m# FIXME: construct an instance of RandomWordsEQ and run lstar\u001B[39;00m\n\u001B[32m     51\u001B[39m \n\u001B[32m     52\u001B[39m \u001B[38;5;66;03m# i dont care\u001B[39;00m\n\u001B[32m     53\u001B[39m rafsdfiojsmdflkjsmdflksjl = RandomWordsEQ(alphabet, sul, \u001B[32m0.9\u001B[39m, \u001B[32m0.05\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m54\u001B[39m dfa = \u001B[43mlstar\u001B[49m\u001B[43m(\u001B[49m\u001B[43msul\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malphabet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrafsdfiojsmdflkjsmdflksjl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mObservationTable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvisualize\u001B[49m()\n\u001B[32m     56\u001B[39m \u001B[38;5;66;03m# You may need to test multiple values for the accuracy and the confidence before obtaining a good model.\u001B[39;00m\n\u001B[32m     57\u001B[39m \u001B[38;5;66;03m# You may need to test multiple values for the accuracy and the confidence before obtaining a good model.\u001B[39;00m\n\u001B[32m     58\u001B[39m \u001B[38;5;66;03m# You may need to test multiple values for the accuracy and the confidence before obtaining a good model.\u001B[39;00m\n",
      "\u001B[31mAttributeError\u001B[39m: 'NoneType' object has no attribute 'visualize'"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "2b6cccf1",
   "metadata": {},
   "source": [
    "### To go further\n",
    "\n",
    "In practice, analyzing the learned DFA by hand is unfeasible. The desired properties are usually expressed via formulas in some logics. For instance, one could express the fact that the printer must automatically lock itself once the timeout occurs as follows:\n",
    "$$\\mathit{state} = \\mathrm{unlocked} \\land \\mathit{action} = \\mathrm{timeout} \\implies \\mathit{state}' = \\mathrm{locked},$$\n",
    "where $\\mathit{state}$ denotes the current state, $\\mathit{action}$ the current action, and $\\mathit{state}'$ the next state of the DFA.\n",
    "\n",
    "We write a collection of such formulas, and check, on each state, whether every formula holds. If (at least) one does not hold, the DFA is incorrect. If the DFA is correctly learned (i.e., if the accuracy and confidence for the PAC framework are well selected), then we can conclude that a system is incorrect.\n",
    "\n",
    "Some other logics instead work on the *traces* of the systems, i.e., the words that are accepted by the DFA. For more information, we refer to *Principles of Model Checking* (Christel Baier and Joost-Pieter Katoen, The MIT Press, 2008)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f5f0825f40bfde21"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
